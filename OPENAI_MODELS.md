# ü§ñ Configuraci√≥n de Modelos de OpenAI

## üìç D√≥nde se Configura el Modelo

El modelo de IA ahora es **configurable desde el archivo `.env`**.

## ‚öôÔ∏è Configuraci√≥n Actual

### Archivos involucrados:

#### 1. `.env` (Configuraci√≥n)
```env
OPENAI_API_KEY=sk-proj-TU_API_KEY_AQUI
OPENAI_MODEL=gpt-4o-mini
```

#### 2. `config/services.php` (Lee desde .env)
```php
'openai' => [
    'api_key' => env('OPENAI_API_KEY'),
    'organization' => env('OPENAI_ORGANIZATION'),
    'model' => env('OPENAI_MODEL', 'gpt-4o-mini'), // Valor por defecto
],
```

#### 3. `app/Services/CommentAnalysisService.php` (Usa la config)
```php
public function __construct()
{
    $this->apiKey = config('services.openai.api_key');
    $this->model = config('services.openai.model', 'gpt-4o-mini');
}
```

## üéØ Modelos Disponibles

### GPT-4 Optimized Series (Recomendados)

#### gpt-4o-mini ‚≠ê [ACTUAL - Mejor opci√≥n para la mayor√≠a]
```env
OPENAI_MODEL=gpt-4o-mini
```
- **Costo**: $0.15 / 1M tokens input, $0.60 / 1M tokens output
- **Velocidad**: ‚ö°‚ö°‚ö° Muy r√°pido
- **Calidad**: ‚≠ê‚≠ê‚≠ê‚≠ê Excelente para an√°lisis
- **Uso**: Perfecto para an√°lisis de comentarios en volumen
- **Contexto**: 128K tokens

#### gpt-4o
```env
OPENAI_MODEL=gpt-4o
```
- **Costo**: $2.50 / 1M tokens input, $10.00 / 1M tokens output
- **Velocidad**: ‚ö°‚ö° R√°pido
- **Calidad**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê M√°xima precisi√≥n
- **Uso**: Cuando necesitas la m√°xima calidad
- **Contexto**: 128K tokens

### GPT-4 Turbo Series

#### gpt-4-turbo
```env
OPENAI_MODEL=gpt-4-turbo
```
- **Costo**: $10.00 / 1M tokens input, $30.00 / 1M tokens output
- **Velocidad**: ‚ö° Lento
- **Calidad**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê M√°xima
- **Uso**: Solo si necesitas m√°xima precisi√≥n y no importa el costo
- **Contexto**: 128K tokens

#### gpt-4-turbo-preview
```env
OPENAI_MODEL=gpt-4-turbo-preview
```
- Versi√≥n preview de GPT-4 Turbo
- M√°s econ√≥mico que gpt-4-turbo est√°ndar

### GPT-3.5 Series (Econ√≥micos)

#### gpt-3.5-turbo
```env
OPENAI_MODEL=gpt-3.5-turbo
```
- **Costo**: $0.50 / 1M tokens input, $1.50 / 1M tokens output
- **Velocidad**: ‚ö°‚ö°‚ö° Muy r√°pido
- **Calidad**: ‚≠ê‚≠ê‚≠ê Buena
- **Uso**: Cuando el presupuesto es muy limitado
- **Contexto**: 16K tokens

#### gpt-3.5-turbo-16k
```env
OPENAI_MODEL=gpt-3.5-turbo-16k
```
- Igual que gpt-3.5-turbo pero con m√°s contexto
- **Contexto**: 16K tokens

## üí∞ Comparaci√≥n de Costos

### An√°lisis de 1,000 comentarios (estimado)

Suponiendo ~200 tokens input + ~300 tokens output por comentario:

| Modelo | Costo Total | Por Comentario |
|--------|-------------|----------------|
| **gpt-4o-mini** ‚≠ê | **~$0.21** | **$0.00021** |
| gpt-3.5-turbo | ~$0.55 | $0.00055 |
| gpt-4o | ~$3.50 | $0.0035 |
| gpt-4-turbo | ~$11.00 | $0.011 |

### An√°lisis de 10,000 comentarios

| Modelo | Costo Total |
|--------|-------------|
| **gpt-4o-mini** ‚≠ê | **~$2.10** |
| gpt-3.5-turbo | ~$5.50 |
| gpt-4o | ~$35.00 |
| gpt-4-turbo | ~$110.00 |

## üìä ¬øQu√© Modelo Usar?

### Para la mayor√≠a de casos: gpt-4o-mini ‚≠ê
```env
OPENAI_MODEL=gpt-4o-mini
```
**‚úÖ Recomendado porque:**
- Excelente calidad para an√°lisis de comentarios
- 7x m√°s barato que gpt-4o
- Suficientemente r√°pido
- El m√°s usado por la comunidad

### Para m√°xima precisi√≥n: gpt-4o
```env
OPENAI_MODEL=gpt-4o
```
**Usa cuando:**
- Necesitas m√°xima precisi√≥n en la categorizaci√≥n
- Analizas comentarios muy complejos o ambiguos
- El presupuesto no es problema
- Son pocos comentarios (< 100)

### Para presupuesto limitado: gpt-3.5-turbo
```env
OPENAI_MODEL=gpt-3.5-turbo
```
**Usa cuando:**
- Tienes presupuesto muy limitado
- Los comentarios son simples y directos
- No necesitas an√°lisis muy profundos
- La categorizaci√≥n b√°sica es suficiente

## üîß C√≥mo Cambiar el Modelo

### Paso 1: Edita el archivo `.env`

```env
# Cambia esta l√≠nea:
OPENAI_MODEL=gpt-4o-mini

# Por el modelo que desees:
OPENAI_MODEL=gpt-4o
```

### Paso 2: Limpia la cach√© de configuraci√≥n

```bash
php artisan config:clear
```

### Paso 3: Verifica el cambio (opcional)

```bash
php artisan tinker
```

Luego en tinker:
```php
config('services.openai.model')
// Deber√≠a mostrar: "gpt-4o" (o el modelo que configuraste)
```

### Paso 4: Listo! ‚úÖ

El pr√≥ximo an√°lisis usar√° el nuevo modelo.

## üß™ Probar Diferentes Modelos

Puedes probar diferentes modelos y comparar resultados:

### An√°lisis con gpt-4o-mini (econ√≥mico)
```env
OPENAI_MODEL=gpt-4o-mini
```
```bash
php artisan youtube:analyze {video_id}
```

### An√°lisis con gpt-4o (preciso)
```env
OPENAI_MODEL=gpt-4o
```
```bash
php artisan youtube:analyze {video_id}
```

**Compara:**
- Calidad de categorizaci√≥n
- Precisi√≥n de insights
- Costo real
- Tiempo de procesamiento

## üìà Recomendaciones por Caso de Uso

### üéì Investigaci√≥n Acad√©mica
**Modelo recomendado:** `gpt-4o`
- Necesitas m√°xima precisi√≥n
- Los datos ser√°n publicados
- Bajo volumen de comentarios

### üíº An√°lisis de Negocio
**Modelo recomendado:** `gpt-4o-mini` ‚≠ê
- Balance perfecto calidad/precio
- Alto volumen de comentarios
- Insights accionables suficientes

### üöÄ Prototipo/Testing
**Modelo recomendado:** `gpt-3.5-turbo`
- Solo est√°s probando funcionalidad
- Bajo presupuesto
- Velocidad > precisi√≥n

### üîç An√°lisis Profundo (Pocos Comentarios)
**Modelo recomendado:** `gpt-4o` o `gpt-4-turbo`
- < 100 comentarios cr√≠ticos
- Cada comentario es muy valioso
- Necesitas m√°ximo detalle

### üìä An√°lisis Masivo (Miles de Comentarios)
**Modelo recomendado:** `gpt-4o-mini` ‚≠ê
- > 1,000 comentarios
- Necesitas insights generales
- Presupuesto controlado

## ‚ö†Ô∏è Consideraciones Importantes

### L√≠mites de Rate
Todos los modelos tienen l√≠mites de requests por minuto:
- **Tier 1**: 500 requests/min
- **Tier 2**: 5,000 requests/min
- **Tier 3**: 10,000 requests/min

El sistema ya incluye un delay de 0.5 segundos entre requests.

### Timeout
Configurado en 60 segundos por request:
```php
->timeout(60)
```

### Tokens M√°ximos
Configurado para respuestas de hasta 500 tokens:
```php
'max_tokens' => 500,
```

Si necesitas respuestas m√°s largas, puedes aumentar este valor.

### Temperature
Configurado en 0.7 para balance creatividad/consistencia:
```php
'temperature' => 0.7,
```

- **0.0**: M√°s determinista (respuestas id√©nticas)
- **0.7**: Balance recomendado
- **1.0**: M√°s creativo (puede variar m√°s)

## üéØ Par√°metros Configurables

Si necesitas ajustar otros par√°metros, edita `CommentAnalysisService.php`:

```php
->post('https://api.openai.com/v1/chat/completions', [
    'model' => $this->model,
    'messages' => [...],
    'temperature' => 0.7,      // ‚Üê Ajustable: 0.0 - 2.0
    'max_tokens' => 500,       // ‚Üê Ajustable: 1 - 4096
    'top_p' => 1.0,           // ‚Üê Opcional: sampling
    'frequency_penalty' => 0,  // ‚Üê Opcional: -2.0 a 2.0
    'presence_penalty' => 0,   // ‚Üê Opcional: -2.0 a 2.0
])
```

## üìö Recursos Adicionales

- [OpenAI Pricing](https://openai.com/pricing)
- [OpenAI Models Documentation](https://platform.openai.com/docs/models)
- [Rate Limits](https://platform.openai.com/docs/guides/rate-limits)
- [Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)

## üîê Seguridad

**‚ö†Ô∏è NUNCA** subas el archivo `.env` a Git:
```bash
# Ya est√° en .gitignore, pero verifica:
git status
# No deber√≠a mostrar .env

# Si aparece, agr√©galo:
echo ".env" >> .gitignore
```

**‚úÖ API Key guardada en:**
- `.env` (local) ‚Üê NO subir a Git
- Variables de entorno del servidor (producci√≥n)

---

**¬øDudas?** El modelo actual `gpt-4o-mini` es excelente para el 95% de casos. 
Solo cambia si tienes necesidades espec√≠ficas. üöÄ
